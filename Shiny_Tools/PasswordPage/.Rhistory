knitr::opts_chunk$set(echo = TRUE)
library('RPostgreSQL')
install.packages("RPostgreSQL")
library('RPostgreSQL')
pg = dbDriver("PostgreSQL")
con = dbConnect(pg, user="postgres", password="alfonstini642856",
host="192.168.1.75", port=5432, dbname="")
knitr::opts_chunk$set(echo = TRUE)
library('RPostgreSQL')
## Loading required package: DBI
pg = dbDriver("PostgreSQL")
# Local Postgres.app database; no password by default
# Of course, you fill in your own database information here.
con = dbConnect(pg, user="postgres", password="alfonstini642856",
host="178.83.109.254", port=5432, dbname="portfolio")
library('RPostgreSQL')
## Loading required package: DBI
pg = dbDriver("PostgreSQL")
# Local Postgres.app database; no password by default
# Of course, you fill in your own database information here.
con = dbConnect(pg, user="postgres", password="alfonstini642856",
host="178.83.109.254", port=5432, dbname="portfolio")
install.packages("RPostgreSQL")
install.packages("RPostgreSQL")
install.packages("RPostgreSQL")
install.packages("RPostgreSQL")
install.packages("RPostgreSQL")
knitr::opts_chunk$set(echo = TRUE)
library('RPostgreSQL')
## Loading required package: DBI
pg = dbDriver("PostgreSQL")
# Local Postgres.app database; no password by default
# Of course, you fill in your own database information here.
con = dbConnect(pg, user="postgres", password="alfonstini642856",
host="178.83.109.254", port=5432, dbname="portfolio")
library('RPostgreSQL')
## Loading required package: DBI
pg = dbDriver("PostgreSQL")
# Local Postgres.app database; no password by default
# Of course, you fill in your own database information here.
con = dbConnect(pg, user="postgres", password="alfonstini642856",
host="178.83.109.254", port=5432, dbname="portfolio")
library('RPostgreSQL')
## Loading required package: DBI
pg = dbDriver("PostgreSQL")
# Local Postgres.app database; no password by default
# Of course, you fill in your own database information here.
con = dbConnect(pg, user="homeassistant", password="alfonstini642856",
host="192.168.1.75", port=5432, dbname="")
library('RPostgreSQL')
## Loading required package: DBI
pg = dbDriver("PostgreSQL")
IP=192.168.1.75
library('RPostgreSQL')
## Loading required package: DBI
pg = dbDriver("PostgreSQL")
IP="192.168.1.75"
# Local Postgres.app database; no password by default
# Of course, you fill in your own database information here.
con = dbConnect(pg, user="postgres", password="alfonstini642856",
host=IP, port=5432, dbname="portfolio")
library('RPostgreSQL')
## Loading required package: DBI
pg = dbDriver("PostgreSQL")
IP="192.168.1.75"
# Local Postgres.app database; no password by default
# Of course, you fill in your own database information here.
con = dbConnect(pg, user="postgres", password="alfonstini642856",
host=IP, port=5432, dbname="portfolio")
```{r pressure, echo=FALSE}
library('RPostgreSQL')
## Loading required package: DBI
pg = dbDriver("PostgreSQL")
IP="lcoalhost"
# Local Postgres.app database; no password by default
# Of course, you fill in your own database information here.
con = dbConnect(pg, user="postgres", password="alfonstini642856",
host=IP, port=5432, dbname="dvdrental")
library('RPostgreSQL')
## Loading required package: DBI
pg = dbDriver("PostgreSQL")
IP="localhost"
# Local Postgres.app database; no password by default
# Of course, you fill in your own database information here.
con = dbConnect(pg, user="postgres", password="alfonstini642856",
host=IP, port=5432, dbname="dvdrental")
dbListTables(con)
install.packages("tesseract")
install.packages("tesseract")
knitr::opts_chunk$set(echo = TRUE)
img <- image_read("http://jeroen.github.io/images/testocr.png")
library(tesseract)
img <- image_read("http://jeroen.github.io/images/testocr.png")
library(httr)
img <- image_read("http://jeroen.github.io/images/testocr.png")
install.packages("magick")
library(magick)
img <- image_read("http://jeroen.github.io/images/testocr.png")
print(img)
cat(image_ocr(img))
URL="http://image.slidesharecdn.com/introduction-english-i-1220212391247715-9/95/introduction-english-i-2-728.jpg?cb=1220187175"
img <- image_read(URL)
print(img)
cat(image_ocr(img))
install.packages("dplyr")
install.packages("dplyr")
install.packages("tidyverse")
knitr::opts_chunk$set(echo = TRUE)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
View(segmentationOriginal)
View(segmentationOriginal)
inTrain <- createDataPartition(y = segmentationOriginal$Case, p = 0.6,
list = FALSE) # 60% training
training <- segmentationOriginal[inTrain, ]
testing <- segmentationOriginal[-inTrain, ]
set.seed(125)
modFit <- train(Class ~ ., method = "rpart", data = training)
modFit$finalModel
fancyRpartPlot(modFit$finalModel)
suppressMessages(library(rattle))
library(rpart.plot)
fancyRpartPlot(modFit$finalModel)
library(pgmm)
install.packages("pgmm")
data(olive)
olive = olive[, -1]
newdata = as.data.frame(t(colMeans(olive)))
library(pgmm)
data(olive)
olive = olive[, -1]
newdata = as.data.frame(t(colMeans(olive)))
modolive <- train(Area ~ ., method = "rpart", data = olive)
predict(modolive, newdata = newdata)
library(ElemStatLearn)
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1], size = dim(SAheart)[1] / 2, replace = F)
trainSA = SAheart[train, ]
testSA = SAheart[-train, ]
set.seed(13234)
modelSA <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl,
data = trainSA, method = "glm", family = "binomial")
missClass(testSA$chd, predict(modelSA, newdata = testSA))
missClass = function(values, prediction){sum(((prediction > 0.5) * 1) != values) / length(values)}
missClass(testSA$chd, predict(modelSA, newdata = testSA))
missClass(trainSA$chd, predict(modelSA, newdata = trainSA))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
library(randomForest)
order(varImp(modvowel), decreasing = T)
modvowel <- randomForest(y ~ ., data = vowel.train)
order(varImp(modvowel), decreasing = T)
library(caret)
library(gbm)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
rf <- train(y~., method = "rf",data =vowel.train)
#Predicting
pred_rf <- predict(rf, vowel.test)
pred_boost <- predict(boost, vowel.test)
pred_boost <- predict(boost, vowel.test)
library(caret)
library(gbm)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
rf <- train(y~., method = "rf",data =vowel.train)
rf <- train(y~., method = "rf",data =vowel.train)
library(caret)
library(gbm)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
mod_rf <- train(y ~ ., data = vowel.train, method = "rf")
mod_gbm <- train(y ~ ., data = vowel.train, method = "gbm")
pred_rf <- predict(mod_rf, vowel.test)
pred_gbm <- predict(mod_gbm, vowel.test)
confusionMatrix(pred_rf, vowel.test$y)$overall[1]
confusionMatrix(pred_gbm, vowel.test$y)$overall[1]
predDF <- data.frame(pred_rf, pred_gbm, y = vowel.test$y)
# Accuracy among the test set samples where the two methods agree
sum(pred_rf[predDF$pred_rf == predDF$pred_gbm] ==
predDF$y[predDF$pred_rf == predDF$pred_gbm]) /
sum(predDF$pred_rf == predDF$pred_gbm)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
mod_rf <- train(diagnosis ~ ., data = training, method = "rf")
mod_gbm <- train(diagnosis ~ ., data = training, method = "gbm")
mod_lda <- train(diagnosis ~ ., data = training, method = "lda")
pred_rf <- predict(mod_rf, testing)
pred_gbm <- predict(mod_gbm, testing)
pred_lda <- predict(mod_lda, testing)
predDF <- data.frame(pred_rf, pred_gbm, pred_lda, diagnosis = testing$diagnosis)
combModFit <- train(diagnosis ~ ., method = "rf", data = predDF)
combPred <- predict(combModFit, predDF)
# Accuracy using boosting
confusionMatrix(pred_gbm, testing$diagnosis)$overall[1]
## Accuracy
## 0.804878
# Accuracy using linear discriminant analysis
confusionMatrix(pred_lda, testing$diagnosis)$overall[1]
##  Accuracy
## 0.7682927
# Stacked Accuracy
confusionMatrix(combPred, testing$diagnosis)$overall[1]
##  Accuracy
## 0.8170732
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
mod_lasso <- train(CompressiveStrength ~ ., data = training, method = "lasso")
library(elasticnet)
plot.enet(mod_lasso$finalModel, xvar = "penalty", use.color = TRUE)
library(lubridate)  # For year() function below
dat = read.csv("/Users/cheyu/Documents/MOOC/MachineLearning/gaData.csv")
library(lubridate)  # For year() function below
dat = read.csv("C:/R/gaData.csv")
training = dat[year(dat$date) < 2012, ]
testing = dat[(year(dat$date)) > 2011, ]
tstrain = ts(training$visitsTumblr)
library(forecast)
mod_ts <- bats(tstrain)
fcast <- forecast(mod_ts, level = 95, h = dim(testing)[1])
sum(fcast$lower < testing$visitsTumblr & testing$visitsTumblr < fcast$upper) /
dim(testing)[1]
knitr::opts_chunk$set(echo = TRUE)
dim(training)
TrainUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
TestUrl  <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
TrainFile<-"pml-traininig.csv"
TestFile<-"pml-testing.csv"
# download the datasets
if(!file.exists(TrainFile))
{
download.file(TrainUrl,destfile = TrainFile)
}
training <- read.csv(TrainFile)
if(!file.exists(TestFile))
{
download.file(TestUrl,destfile = TestFile)
}
testing  <- read.csv(TestFile)
dim(training)
names(training)
sensorColumns = grep(pattern = "_belt|_arm|_dumbbell|_forearm", names(pml_training_data))
sensorColumns = grep(pattern = "_belt|_arm|_dumbbell|_forearm", names(tarining))
sensorColumns = grep(pattern = "_belt|_arm|_dumbbell|_forearm", names(training))
length(sensorColumns)
sensorColumns = grep(pattern = "_belt|_arm|_dumbbell|_forearm", names(training))
length(sensorColumns)
data = training[, c(sensorColumns,160)]
dim(data)
missingData = is.na(data)
omitColumns = which(colSums(missingData) > 19000)
data = data[, -omitColumns]
dim(data)
table(complete.cases(data))
table(sapply(data[1,], class))
inTrain <- createDataPartition(y=data$classe, p=0.75, list=FALSE)
training <- data[inTrain,]
dim(training)
testing <- data[-inTrain,]
dim(testing)
set.seed(2014)
library(caret)
library(randomForest)
## randomForest 4.6-10
## Type rfNews() to see new features/changes/bug fixes.
time1 = proc.time()
(randForest = randomForest(classe~., data=training, ntree = 500))
missingData = is.na(data)
omitColumns = which(colSums(missingData) > 19000)
data = data[, -omitColumns]
dim(data)
sensorColumns = grep(pattern = "_belt|_arm|_dumbbell|_forearm", names(training))
length(sensorColumns)
data = training[, c(sensorColumns,160)]
TrainUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
TestUrl  <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
TrainFile<-"pml-traininig.csv"
TestFile<-"pml-testing.csv"
# download the datasets
if(!file.exists(TrainFile))
{
download.file(TrainUrl,destfile = TrainFile)
}
training <- read.csv(TrainFile)
if(!file.exists(TestFile))
{
download.file(TestUrl,destfile = TestFile)
}
testing  <- read.csv(TestFile)
dim(training)
names(training)
sensorColumns = grep(pattern = "_belt|_arm|_dumbbell|_forearm", names(training))
length(sensorColumns)
data = training[, c(sensorColumns,160)]
dim(data)
missingData = is.na(data)
omitColumns = which(colSums(missingData) > 19000)
data = data[, -omitColumns]
dim(data)
missingData = is.na(data)
omitColumns = which(colSums(missingData) > 22000)
data = data[, -omitColumns]
dim(data)
TrainUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
TestUrl  <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
TrainFile<-"pml-traininig.csv"
TestFile<-"pml-testing.csv"
# download the datasets
if(!file.exists(TrainFile))
{
download.file(TrainUrl,destfile = TrainFile)
}
training <- read.csv(TrainFile)
if(!file.exists(TestFile))
{
download.file(TestUrl,destfile = TestFile)
}
testing  <- read.csv(TestFile)
dim(training)
names(training)
sensorColumns = grep(pattern = "_belt|_arm|_dumbbell|_forearm", names(training))
length(sensorColumns)
data = training[, c(sensorColumns,160)]
dim(data)
missingData = is.na(data)
omitColumns = which(colSums(missingData) > 22000)
data2 = data[, -omitColumns]
dim(data)
missingData = is.na(data)
omitColumns = which(colSums(missingData) > 22000)
data2 = data[, -omitColumns]
dim(data2)
missingData = is.na(data)
omitColumns = which(colSums(missingData) > 20000)
data2 = data[, -omitColumns]
dim(data2)
missingData = is.na(data)
omitColumns = which(colSums(missingData) > 19000)
data2 = data[, -omitColumns]
dim(data2)
missingData = is.na(data)
omitColumns = which(colSums(missingData) > 19500)
data2 = data[, -omitColumns]
dim(data2)
missingData = is.na(data)
omitColumns = which(colSums(missingData) > 19000)
data2 = data[, -omitColumns]
dim(data2)
table(complete.cases(data))
table(complete.cases(data))
table(sapply(data[1,], class))
TrainUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
TestUrl  <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
TrainFile<-"pml-traininig.csv"
TestFile<-"pml-testing.csv"
# download the datasets
if(!file.exists(TrainFile))
{
download.file(TrainUrl,destfile = TrainFile)
}
training <- read.csv(TrainFile)
if(!file.exists(TestFile))
{
download.file(TestUrl,destfile = TestFile)
}
testing  <- read.csv(TestFile)
dim(training)
names(training)
sensorColumns = grep(pattern = "_belt|_arm|_dumbbell|_forearm", names(training))
length(sensorColumns)
data = training[, c(sensorColumns,160)]
dim(data)
missingData = is.na(data)
omitColumns = which(colSums(missingData) > 19000)
data = data[, -omitColumns]
dim(data)
table(complete.cases(data))
table(sapply(data[1,], class))
set.seed(2014)
library(caret)
inTrain <- createDataPartition(y=data$classe, p=0.75, list=FALSE)
training <- data[inTrain,]
dim(training)
testing <- data[-inTrain,]
dim(testing)
inTrain <- createDataPartition(y=data$classe, p=0.75, list=FALSE)
training <- data[inTrain,]
dim(training)
testing <- data[-inTrain,]
dim(testing)
library(randomForest)
## randomForest 4.6-10
## Type rfNews() to see new features/changes/bug fixes.
time1 = proc.time()
(randForest = randomForest(classe~., data=training, ntree = 500))
gimples(data)
str(data)
View(data)
View(data)
library(shiny); runApp('C:/OneDrive/7_DataScience/02_Visual Studio/2_GitHub/Shiny_Tools/Shiny_Tools/PasswordPage/Shiny_password_NEW.R')
runApp('C:/OneDrive/7_DataScience/02_Visual Studio/2_GitHub/Shiny_Tools/Shiny_Tools/PasswordPage/Shiny_password_NEW.R')
runApp('C:/OneDrive/7_DataScience/02_Visual Studio/2_GitHub/Shiny_Tools/Shiny_Tools/PasswordPage/Shiny_password_NEW.R')
library(shiny); runApp('Shiny_password_NEW.R')
runApp('Shiny_password_NEW.R')
